{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":88046,"databundleVersionId":10229277,"sourceType":"competition"},{"sourceId":11384,"sourceType":"modelInstanceVersion","modelInstanceId":6216,"modelId":3301}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T10:28:02.485555Z","iopub.execute_input":"2025-03-23T10:28:02.485952Z","iopub.status.idle":"2025-03-23T10:28:02.918029Z","shell.execute_reply.started":"2025-03-23T10:28:02.485891Z","shell.execute_reply":"2025-03-23T10:28:02.916779Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/gemma/transformers/2b/2/model.safetensors.index.json\n/kaggle/input/gemma/transformers/2b/2/gemma-2b.gguf\n/kaggle/input/gemma/transformers/2b/2/config.json\n/kaggle/input/gemma/transformers/2b/2/model-00001-of-00002.safetensors\n/kaggle/input/gemma/transformers/2b/2/model-00002-of-00002.safetensors\n/kaggle/input/gemma/transformers/2b/2/tokenizer.json\n/kaggle/input/gemma/transformers/2b/2/tokenizer_config.json\n/kaggle/input/gemma/transformers/2b/2/special_tokens_map.json\n/kaggle/input/gemma/transformers/2b/2/.gitattributes\n/kaggle/input/gemma/transformers/2b/2/tokenizer.model\n/kaggle/input/gemma/transformers/2b/2/generation_config.json\n/kaggle/input/santa-2024/sample_submission.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom collections import Counter\nfrom tqdm import tqdm\nimport random, pickle, math, warnings\n#warnings.simplefilter('ignore')\n\np = '/kaggle/input/santa-2024/sample_submission.csv'\ndf = pd.read_csv(p) # \tid \ttext\nprint(df['text'].map(lambda x: len(str(x).split(' '))).values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T10:28:02.920110Z","iopub.execute_input":"2025-03-23T10:28:02.920597Z","iopub.status.idle":"2025-03-23T10:28:02.947906Z","shell.execute_reply.started":"2025-03-23T10:28:02.920560Z","shell.execute_reply":"2025-03-23T10:28:02.946865Z"}},"outputs":[{"name":"stdout","text":"[ 10  20  20  30  50 100]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"tokens = df.text.values\ntokens = ' '.join(tokens)\ntokens = tokens.split(' ')\ntokens = dict(Counter(tokens))\nprint(len(tokens))\n#print(tokens)\nprint('-'*20)\nprint(' '.join(k for k in tokens))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T10:28:02.949626Z","iopub.execute_input":"2025-03-23T10:28:02.950060Z","iopub.status.idle":"2025-03-23T10:28:02.957243Z","shell.execute_reply.started":"2025-03-23T10:28:02.950012Z","shell.execute_reply":"2025-03-23T10:28:02.956076Z"}},"outputs":[{"name":"stdout","text":"89\n--------------------\nadvent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge walk give jump drive bake the sleep night laugh and yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh workshop stocking holly jingle beard naughty nice sing of is eat visit relax unwrap hohoho candle poinsettia snowglobe peppermint eggnog fruitcake chocolate candy puzzle game doll toy wonder believe dream hope peace joy merry season greeting card wrapping paper bow cookie milk star wish wreath angel to in that have it not with as you from we kaggle\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import transformers, torch\nimport gc, os, logging\nfrom math import exp\nfrom typing import List, Optional, Union\n\nos.environ['OMP_NUM_THREADS'] = '1'\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\nDEVICE = torch.device('cpu')\nMODEL_PATH = \"/kaggle/input/gemma/transformers/2b/2\"\n\nclass ParticipantVisibleError(Exception):\n    print(Exception)\n    pass\n\nclass PerplexityCalculator:\n    def __init__(self):\n        self.tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_PATH)\n        self.model = transformers.AutoModelForCausalLM.from_pretrained(\n            MODEL_PATH, device_map=\"auto\", torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n        )\n        self.loss_fct = torch.nn.CrossEntropyLoss(reduction='none')\n        self.model.eval()\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.model.to(self.device)\n\n    def get_perplexity(self, input_texts: Union[str, List[str]]) -> Union[float, List[float]]:\n        single_input = isinstance(input_texts, str)\n        input_texts = [input_texts] if single_input else input_texts\n        loss_list = []\n\n        with torch.no_grad():\n            for text in input_texts:\n                text_with_special = f\"{self.tokenizer.bos_token}{text}{self.tokenizer.eos_token}\"\n                minputs = self.tokenizer(text_with_special, return_tensors='pt', add_special_tokens=False)\n                minputs = {k: v.to(self.device) for k, v in minputs.items()}\n                output = self.model(**minputs, use_cache=False)\n                logits = output['logits']\n                slogits = logits[..., :-1, :].contiguous()\n                slabels = minputs['input_ids'][..., 1:].contiguous()\n                loss = self.loss_fct(slogits.view(-1, slogits.size(-1)), slabels.view(-1))\n                sequence_loss = loss.sum() / len(loss)\n                loss_list.append(sequence_loss.cpu().item())\n\n        ppl = [exp(i) for i in loss_list]\n        return ppl[0] if single_input else ppl\n\nscorer = PerplexityCalculator()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T10:28:02.959391Z","iopub.execute_input":"2025-03-23T10:28:02.960246Z","iopub.status.idle":"2025-03-23T10:28:35.299797Z","shell.execute_reply.started":"2025-03-23T10:28:02.960190Z","shell.execute_reply":"2025-03-23T10:28:35.298441Z"}},"outputs":[{"name":"stdout","text":"<class 'Exception'>\n","output_type":"stream"},{"name":"stderr","text":"`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\nGemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n`config.hidden_activation` if you want to override this behaviour.\nSee https://github.com/huggingface/transformers/pull/29402 for more details.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1cd37b67fff4d5394c2e02f839826f0"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"tokens = \"advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge walk give jump drive bake the sleep night laugh and yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh workshop stocking holly jingle beard naughty nice sing of is eat visit relax unwrap hohoho candle poinsettia snowglobe peppermint eggnog fruitcake chocolate candy puzzle game doll toy wonder believe dream hope peace joy merry season greeting card wrapping paper bow cookie milk star wish wreath angel to in that have it not with as you from we kaggle\"\ntext_with_special = f\"{scorer.tokenizer.bos_token}{tokens}{scorer.tokenizer.eos_token}\"\nminputs = scorer.tokenizer(text_with_special, return_tensors='pt', add_special_tokens=False,)\nminputs['input_ids']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T10:28:35.301622Z","iopub.execute_input":"2025-03-23T10:28:35.302365Z","iopub.status.idle":"2025-03-23T10:28:35.317610Z","shell.execute_reply.started":"2025-03-23T10:28:35.302295Z","shell.execute_reply":"2025-03-23T10:28:35.316314Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"tensor([[     2, 104828,  67905,  52931,   2730,  43485, 136507,   7727, 165493,\n          29138, 103360,   1513,  80108,    541,   5376,   2734,   9902,   6109,\n          44528,    573,   6284,   3354,  10084,    578,    597,   1731,  23675,\n          42768,  17196,  22867,  12083, 138763, 198447,  16621,  99946,  16573,\n           2660,  14111, 155702,  20257,  77515, 108548, 204063,  38175,  97840,\n           4866,   2800,    576,    603,   7812,   3532,  10228,    748,  14660,\n           1965, 215898,  28162,  83096,    881,   9437,   8529, 112671, 149218,\n           7815,   1312,    869,   9471,  23144,  13171,  25720,  24754,   2398,\n           7474,  12849,   5144,   4564,   6523,   4077,   7124,  10300,  46301,\n           3891,  32338,   4076,  56178,   4368,   7181,  17467,   9512,   2343,\n           6199,  58409,  22448,    577,    575,    674,    791,    665,    780,\n            675,    685,    692,    774,    783, 124555,   2315,      1]])"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"past = {'reindeer mistletoe elf scrooge gingerbread chimney fireplace ornament family advent': 495.6812574407127,\n 'reindeer mistletoe elf gingerbread ornament advent family fireplace chimney sleep drive walk jump laugh give and bake the night scrooge': 514.3236249412977,\n 'magi yuletide cheer grinch carol holly jingle naughty nice polar beard sleigh chimney workshop nutcracker holiday ornament decorations gifts stocking': 327.18895045897995,\n 'sleigh of the magi yuletide cheer grinch is unwrap gifts decorations ornament holly stocking and chimney naughty nice polar beard nutcracker visit workshop eat relax carol sing holiday cheer jingle': 327.33220436011106,\n 'wreath merry have and season hohoho to you from the star of wonder workshop that it not with joy we believe hope peace fruitcake chocolate candy peppermint candle snowglobe angel poinsettia wrapping paper bow greeting card cookie milk wish dream fireplace kaggle toy doll game night puzzle eggnog as in': 222.93269021691262,\n 'decorations eggnog yuletide poinsettia fruitcake scrooge nutcracker mistletoe holly wreath gingerbread cookie snowglobe reindeer angel star merry and the season of joy and wonder and peace to you from the family of the grinch holiday cheer is not as cheer unwrap gifts laugh hohoho sing carol in sleigh drive visit chimney chimney elf naughty nice eat bake sleep dream chocolate peppermint ornament stocking fireplace fireplace advent candle wish hope give card ornament wrapping paper toy doll bow game night night puzzle candy walk jingle jump relax believe it with we have that kaggle workshop workshop polar beard milk greeting magi': 120.92163009638384}\nprint(len(past))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T10:28:35.319338Z","iopub.execute_input":"2025-03-23T10:28:35.319800Z","iopub.status.idle":"2025-03-23T10:28:35.344791Z","shell.execute_reply.started":"2025-03-23T10:28:35.319750Z","shell.execute_reply":"2025-03-23T10:28:35.343608Z"}},"outputs":[{"name":"stdout","text":"6\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"%%time\n\ndef get_best_plex(df, past):\n    l = 2\n    df['score'] = df['text'].map(lambda x: scorer.get_perplexity(x))\n    print(np.mean(df['score'].values))\n    for r in range(len(df)):\n        #get best past\n        print(\"row: \", r, df.at[r, 'score'])\n        t = df['text'][r].split(' ')\n        for k in past:\n            kp = k.split(' ')\n            if len(kp)==len(t):\n                if sorted(kp) == sorted(t):\n                    if df['score'][r] > past[k]:\n                        df.at[r, 'score'] = past[k]\n                        df.at[r, 'text'] = k\n        print(\"row: \", r, df.at[r, 'score'])\n        #for i in tqdm(range(l)):\n        for i in range(l):\n            t = df['text'][r].split(' ')\n            random.shuffle(t)\n            t = ' '.join(t)\n            if t not in past:\n                s = scorer.get_perplexity(t)\n                past[t]=s\n                if s < df['score'][r]:\n                    df.at[r, 'score'] = s\n                    df.at[r, 'text'] = t\n                    print(r, i, \"New Score: \", s, np.mean(df['score'].values))\n        with open('past0.pickle', 'wb') as f:\n            pickle.dump(past, f, protocol=pickle.HIGHEST_PROTOCOL)\n    print('MEAN SCORE: ', np.mean(df['score'].values))\n    return df[['id','text']], past\n\ndf, past = get_best_plex(df, past)\ndf.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T10:28:35.346092Z","iopub.execute_input":"2025-03-23T10:28:35.346509Z","iopub.status.idle":"2025-03-23T10:29:44.737701Z","shell.execute_reply.started":"2025-03-23T10:28:35.346473Z","shell.execute_reply":"2025-03-23T10:29:44.735976Z"}},"outputs":[{"name":"stderr","text":"Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n","output_type":"stream"},{"name":"stdout","text":"1018.7141148854306\nrow:  0 1350.9216564227258\nrow:  0 495.6812574407127\nrow:  1 2146.111641264015\nrow:  1 514.3236249412977\nrow:  2 872.250522619955\nrow:  2 327.18895045897995\nrow:  3 834.3357780659894\nrow:  3 327.33220436011106\nrow:  4 489.6441270405202\nrow:  4 222.93269021691262\nrow:  5 419.02096389937867\nrow:  5 120.92163009638384\nMEAN SCORE:  334.73005958573293\nCPU times: user 2min 12s, sys: 2.65 s, total: 2min 15s\nWall time: 1min 9s\n","output_type":"stream"}],"execution_count":7}]}